{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <img style=\"float:right;\" src=\"images/snext-logo.png\"/>\n",
    "    <div style=\"float:left;color:#626262;padding-top:30px\"><h1>Exercise: Supervised learning in Python with scikit-learn</h1></div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebooks contains the skeleton of a simple data analytics documentation that benchmarks two models on a given dataset.\n",
    "\n",
    "Walk through the analysis be executing the cells one by one, complete the contained assignments then apply the learnings to a new case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. Case description\n",
    "\n",
    "### Business Problem\n",
    "In financial institutions, the process of loan approval and determining the interest rate offered is critical in mitigating potential risks and maximizing returns. The decision-making process involves assessing the risk of each loan application based on various factors, such as credit score, income, and past repayment history. The assessment informs the bank of the probability of the borrower defaulting on the loan, which affects the interest rate offered to the applicant. Therefore, having a reliable and accurate risk assessment model is essential for financial institutions to make informed decisions.\n",
    "\n",
    "### Research Problem\n",
    "The research problem is to develop a classification model that can accurately classify loan applications into risk or no-risk categories. The model will review historical data on past loan applications and outcomes to identify patterns and predict the probability of the loan defaulting. Based on the model output, the loan applications shall be classified into those with low or high risk. The outcome of the model will help the bank make informed decisions on the loan amount, interest rates, and payment schedules, thus mitigating potential risks and enhancing returns.\n",
    "\n",
    "### Training Data\n",
    "The training dataset will consist of past loan applications and the corresponding outcomes. The data points collected will include the borrower's credit score, income, years of experience, and financial history such as investments, credit card debt, mortgage information, and other assets. The outcome variable will be a binary classification of either a loan default or no default. The model will undergo a series of tests using cross-validation techniques before implementation.\n",
    "\n",
    "### Exercise\n",
    "Developing a risk assessment model for loan applications is crucial for financial institutions to minimize risks and maximize profitability. Students in a university can engage in this problem to gain hands-on experience with data analysis and predictive modeling. The project will involve building and benchmarking classification models that can accurately classify loan applications, considering various features to predict if a loan is likely to default or not. The project will allow students to learn the methods of data pre-processing, model building and evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. Data loading, preparation and exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load required libraries and jupyter extenions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import model_selection, linear_model, tree\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "# load Jupyter plugins to enable SQL to query data and display plots inline (below the code cell)\n",
    "\n",
    "%load_ext sql\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unzip SQlite database\n",
    "!unzip -o -d data data/snext-data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql sqlite:///data/snext-database.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = %sql SELECT * FROM credit_ger\n",
    "df = data.DataFrame()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set index, shorten/unify feature names\n",
    "df = df.set_index([\"id\"])\n",
    "df = df.rename({\n",
    "    \"Age\": \"age\",\n",
    "    \"Sex\": \"sex\",\n",
    "    \"Job\": \"job\",\n",
    "    \"Housing\": \"housing\",\n",
    "    \"Saving_accounts\": \"savings\", \n",
    "    \"Checking_account\": \"cash\",\n",
    "    \"Credit_amount\": \"amount\",\n",
    "    \"Duration\": \"duration\",\n",
    "    \"Purpose\": \"purpose\",\n",
    "    \"Risk\": \"risk\"\n",
    "}, axis=\"columns\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "### <span style=\"color:#46B7E9;\">Assignment: Explore the dataset to gain some understanding about the contained credit applications</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. Feature Engineering\n",
    "What is it about?\n",
    "\n",
    "> Feature engineering is the process of preparing data for algorithms by making features accessible. Typically in this step, domain knowledge of the modeler is incorporated into the dataset.\n",
    "\n",
    "Feature engineering is an important step in machine learning as it can greatly affect the accuracy of the models. Without feature engineering, the models may not be able to capture the important information in the data. It requires not only technical skills but also a deep understanding of the problem and domain knowledge. By preparing the features carefully, we can improve the models' performance and make better predictions.\n",
    "\n",
    "In this example, we focus on the minimum: the selected machine learning methods should be able to handle the dataset technically. There are several string features (nominal scale) in the dataset that cannot be directly processed. Therefore, it is useful to recode them into numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframes for processed data\n",
    "# X will hold the input features (input for the model)\n",
    "# y will hold the label (the desired output of the model)\n",
    "X = pd.DataFrame()\n",
    "y = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dummy encoding for binary, nominal features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[\"risk\"] = (df.risk == \"bad\")*1   # *1 translates True/False to 0/1\n",
    "X[\"male\"] = (df.sex == \"male\")*1\n",
    "\n",
    "print(X.male.value_counts())\n",
    "print(\"\")\n",
    "print(y.risk.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One-Hot-Encoding for nominal features with multiple categories\n",
    "This method creates one variable for each category of a nominal feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = df[\"housing\"]\n",
    "one_hot_encoded = pd.get_dummies(example)*1\n",
    "pd.concat([example, one_hot_encoded], axis=1).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply one-hot-encoding to nominal features with multiple categories\n",
    "\n",
    "df.purpose = df.purpose.str.slice(0,8) # shorten purpose string\n",
    "\n",
    "encoded_features = pd.get_dummies(df[[\"housing\",\"purpose\",\"savings\",\"cash\"]])\n",
    "X = pd.concat([X, encoded_features], axis=1) # append features to dataframe X with training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all metric variables can remain as is, so we append them to the training data \n",
    "X = pd.concat([X,df[[\"age\", \"amount\", \"duration\"]]], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "### <span style=\"color:#46B7E9;\">Assignment: Inspect the recoded training data X and training data labels y</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split training data in training, and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check how many (rows, columns) each dataframe holds\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seperate 20% of training data as \"test data\" that will be set aside and not be used for model training\n",
    "# we'll use this data later on to check the model performance with data it hasn't \"seen\" yet\n",
    "\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "### <span style=\"color:#46B7E9;\">Assignment: Think about how many rows and rolumns the splitted dataframes hold before executing the next cell</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: X_train has ... rows, ... columns, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the shape of the resulting dataframes (rows, columns)\n",
    "print (f\"Training data shape: {X_train.shape}\")\n",
    "print (f\"Test data shape: {X_test.shape}\")\n",
    "print (f\"Training data labels: {y_train.shape}\")\n",
    "print (f\"Test data labels: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the regression model\n",
    "reg = sklearn.linear_model.LogisticRegression()\n",
    "reg = reg.fit(X_train, y_train[\"risk\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyze weight factors\n",
    "stat = pd.DataFrame([X.columns, reg.coef_.ravel()]).transpose()\n",
    "stat = stat.sort_values(by=[1])\n",
    "stat = stat[abs(stat[1])>0.05]   # only important parameters\n",
    "stat = stat.set_index(0)\n",
    "stat.plot(kind=\"barh\", title=\"Regression coefficients of features\", legend=False, xlabel=\"Coefficient value\", ylabel=\"Coefficient name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "### <span style=\"color:#46B7E9;\">Assignment: Interpret the diagram with regression coefficients</span>\n",
    "1. What is the meaning of an regression coefficient?\n",
    "2. From the diagram: What are the top factors making a credit application look more or less risky? Hint: Label encoding in y is 0=no risk, 1=risk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the tree\n",
    "tree = sklearn.tree.DecisionTreeClassifier(min_samples_leaf=20) # split nodes until only x samples (credit application cases) remain in a node\n",
    "tree = tree.fit(X_train, y_train) # only use training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize tree\n",
    "fig, ax = plt.subplots(1,1,figsize=(35,15))\n",
    "plt.style.use('default')  # Bug in scikit-learn: Wenn Seaborn-Style gesetzt, wird der Tree nicht korrekt dargestellt, daher erst zur√ºcksetzen\n",
    "t = sklearn.tree.plot_tree(tree, ax=ax, class_names=True, label=\"root\", precision=2, feature_names=X.columns, fontsize=12, proportion=True, filled=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "### <span style=\"color:#46B7E9;\">Assignment: Compare the top regression coefficients with the key splits of the descision tree</span>\n",
    "1. Recap or research/rewatch the videos from the course to answer this questions: How does a feature becomes important in each of the algorithms?\n",
    "2. What do you think: should both algorithms rely primarily on the same features?\n",
    "3. Compare the three most important features in the tree visualization and regression coefficient diagram to check your hypothesis. Are the important features identical, overlapping or different?\n",
    "4. Think and/or research: under which circumstances will both algorithms not pick the same features as the most important?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Evaluation and Benchmarking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple metric: Average Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Average Precision DecisionTree: {tree.score(X_train, y_train)} with training data, {tree.score(X_test, y_test)} with test data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "### <span style=\"color:#46B7E9;\">Assignment: Interpret the quality metric</span>\n",
    "1. Research the exact definition, how the scikit-learn library calculates the average precision.\n",
    "2. Think about under what circumstances this metric might be misleading!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay.from_predictions(y_test, reg.predict(X_test), display_labels=[\"no-risk\",\"risk\"], cmap=plt.cm.Blues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay.from_predictions(y_test, tree.predict(X_test), display_labels=[\"no-risk\",\"risk\"], cmap=plt.cm.Blues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "---\n",
    "### <span style=\"color:#46B7E9;\">Assignment: Interpret the confusion matrices</span>\n",
    "1. The matrices show two kinds of error, which one is \"bigger\" in terms of how often it occurres?\n",
    "2. Which of the problems is worse business-wise?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision and Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When analyzing a Confusion Matrix, there are two facets of errors that we are particularly interested in. These can be framed as two questions: \n",
    "- how many of the accused (risky credits) were correctly identified, and\n",
    "- how many of the risky loans were detected?\n",
    "\n",
    "These questions are answered by the metrics Precision and Recall (read more [here](https://en.wikipedia.org/wiki/Precision_and_recall)).\n",
    "\n",
    "Precision refers to the **proportion of actual credit risks among the predicted credit risks**, while Recall refers to the **proportion of identified risks among all risky loans**. \n",
    "\n",
    "From a business perspective, the types of errors have varying weights and consequences: falsely assuming risk results in missed opportunities for business growth, while failing to identify risk can lead to substantial financial losses. As such, Recall, with its emphasis on identifying risks, should be valued more highly than Precision.\n",
    "\n",
    "It is important to understand Precision and Recall as they represent two key metrics for evaluating predictive models. Precision measures the ability of the model to avoid making false positive predictions, while Recall measures the ability to detect all positive instances. In other words, Precision identifies how many of the predicted risks were actual risks, and Recall indicates how many of the actual risks were predicted.\n",
    "\n",
    "Ultimately, it is crucial for businesses to use models that optimize both Precision and Recall. An overly strict model may have high Precision but low Recall, resulting in missed opportunities for growth. On the other hand, an overly lenient model may have high Recall but low Precision, leading to a greater number of false positives and missed opportunities. Finding the right balance between these two metrics is key to building a successful predictive model and avoiding costly errors down the line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_precision = precision_score(y_test.values.ravel(), tree.predict(X_test))\n",
    "tree_recall    = recall_score(y_test.values.ravel(), tree.predict(X_test))\n",
    "\n",
    "reg_precision = precision_score(y_test.values.ravel(), reg.predict(X_test))\n",
    "reg_recall    = recall_score(y_test.values.ravel(), reg.predict(X_test))\n",
    "\n",
    "print(\"Tree:       Precision {:.2f}%, Recall {:.2f}%\".format(100 * tree_precision, 100 * tree_recall))\n",
    "print(\"Regression: Precision {:.2f}%, Recall {:.2f}%\".format(100 * reg_precision, 100 * reg_recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "### <span style=\"color:#46B7E9;\">Assignment: Interpret the precision and recall metric</span>\n",
    "1. What do these metrics tell you about the prediction quality? What new strenghts and weaknesses can you uncover?\n",
    "2. How relevant is this difference between the models from a business side?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing prediction errors\n",
    "To discover areas for improvement, let's examine the biggest mistakes made by the model. To demonstrate the process we look at the predictions of the decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = tree.predict(X_train)                                   # predicion from tree model\n",
    "Y_prob = tree.predict_proba(X_train)                             # probabilities for classes 0 and 1\n",
    "df_pred = pd.DataFrame(Y_pred, columns=[\"prediction\"])           \n",
    "df_prob = pd.DataFrame(Y_prob, columns=[\"Prob_0\", \"Prob_1\"])\n",
    "df_err = pd.concat([X_test, y_test, df_pred, df_prob], axis=1)   # assemble dataframe with all diagnostic information\n",
    "\n",
    "df_err.dropna(inplace=True)                                      # remove all data with missing values (training data, we're look at test data only)\n",
    "\n",
    "df_err = df_err[df_err.risk != df_err.prediction]\n",
    "df_err[\"error_size\"] = df_err[[\"Prob_0\",\"Prob_1\"]].max(axis=1)\n",
    "\n",
    "df_err.sort_values(\"error_size\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's visualize some characteristics of the misclassified credit applications.\n",
    "\n",
    "In the first row, we describe the misclassified applications, in the second row the whole test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,3, figsize=(12,6))\n",
    "\n",
    "df_err.amount.plot(kind=\"kde\", ax=ax[0,0])\n",
    "df_err.duration.plot(kind=\"kde\", ax=ax[0,1])\n",
    "df_err.age.plot(kind=\"kde\", ax=ax[0,2])\n",
    "\n",
    "X_test.amount.plot(kind=\"kde\", ax=ax[1,0])\n",
    "X_test.duration.plot(kind=\"kde\", ax=ax[1,1])\n",
    "X_test.age.plot(kind=\"kde\", ax=ax[1,2])\n",
    "\n",
    "ax[0,0].set_title(\"absolute error\")\n",
    "ax[0,1].set_title(\"amount\")\n",
    "ax[0,2].set_title(\"duration\")\n",
    "ax[0,3].set_title(\"age\")\n",
    "\n",
    "#[a.grid(linestyle=\"--\", linewidth=.5) for a in ax]\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "### <span style=\"color:#46B7E9;\">Assignment: Interpret the findings and conduct additional analyis</span>\n",
    "1. Which credit applications does the tree struggle whith?\n",
    "2. Create some hypotheses: What could be the cause? How could we mitigate the problem?\n",
    "   - Is the model not capable enough?\n",
    "   - Are we missing data that could shed more light on these specific cases?\n",
    "   - ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
